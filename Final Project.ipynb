{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48f20796",
   "metadata": {},
   "source": [
    "Adding relevant libraries to the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e4dfbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "import requests\n",
    "import html\n",
    "import random\n",
    "import pandas as pd\n",
    "import time\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import zscore\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687c1983",
   "metadata": {},
   "source": [
    "# Crawling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dc892be",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (10098321.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\shayl\\AppData\\Local\\Temp\\ipykernel_28992\\10098321.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    Creating the main function \"get_data_from_goodreads_url\" using BeautifulSoup and requests libaries. The function takes a URL as input and retrieves specific information from the HTML content of the webpage,the desired information is located in specific HTML elements with specific classes or attributes.\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Creating the main function \"get_data_from_goodreads_url\" using BeautifulSoup and requests libaries. The function takes a URL as input and retrieves specific information from the HTML content of the webpage,the desired information is located in specific HTML elements with specific classes or attributes.\n",
    "\n",
    "And finally, the data of that book is exported into DF\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3c7a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_goodreads_url(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    try:\n",
    "        name = soup.find('h1', class_='Text Text__title1').get_text()\n",
    "    except AttributeError:\n",
    "        name = None\n",
    "\n",
    "    try:\n",
    "        author = soup.find('span', class_='ContributorLink__name').get_text()\n",
    "    except AttributeError:\n",
    "        author = None\n",
    "\n",
    "    try:\n",
    "        counts_to_extract = soup.find('div', class_='RatingStatistics__meta')\n",
    "        ratings_count = counts_to_extract.find('span', attrs={'data-testid': 'ratingsCount'}).get_text()\n",
    "        ratings_count_array = ratings_count.split('\\xa0')\n",
    "    except AttributeError:\n",
    "        ratings_count_array = [None]\n",
    "\n",
    "    try:\n",
    "        counts_to_extract = soup.find('div', class_='RatingStatistics__meta')\n",
    "        reviews_count = counts_to_extract.find('span', attrs={'data-testid': 'reviewsCount'}).get_text()\n",
    "        reviews_count_array = reviews_count.split('\\xa0')\n",
    "    except AttributeError:\n",
    "        reviews_count_array = [None]\n",
    "\n",
    "    try:\n",
    "        rating_to_extract = soup.find('a', class_='RatingStatistics RatingStatistics__interactive')\n",
    "        rating_num = rating_to_extract.find('div', class_='RatingStatistics__rating').get_text()\n",
    "    except AttributeError:\n",
    "        rating_num = None\n",
    "\n",
    "    try:\n",
    "        booked_details = soup.find('div', class_='BookDetails')\n",
    "        Featured_Details = booked_details.find('div', class_='FeaturedDetails')\n",
    "        length = Featured_Details.find('p', attrs={'data-testid': 'pagesFormat'}).get_text()\n",
    "        length_array = length.split(\" \")\n",
    "        length_var = length_array[0]\n",
    "    except AttributeError:\n",
    "        length_var = None\n",
    "\n",
    "    try:\n",
    "        date = Featured_Details.find('p', attrs={'data-testid': 'publicationInfo'}).get_text()\n",
    "        date_array = date.split(\", \")\n",
    "        date_var = date_array[-1]\n",
    "    except AttributeError:\n",
    "        date_var = None\n",
    "\n",
    "    try:\n",
    "        ratings = soup.find('div', class_='RatingsHistogram RatingsHistogram__interactive')\n",
    "        ratings_array = ratings.find_all('div', class_='RatingsHistogram__bar')\n",
    "\n",
    "        five_raw = ratings_array[0].find('div', class_='RatingsHistogram__labelTotal').get_text()\n",
    "        five_votes = five_raw.split(\" \")[0]\n",
    "\n",
    "        four_raw = ratings_array[1].find('div', class_='RatingsHistogram__labelTotal').get_text()\n",
    "        four_votes = four_raw.split(\" \")[0]\n",
    "\n",
    "        three_raw = ratings_array[2].find('div', class_='RatingsHistogram__labelTotal').get_text()\n",
    "        three_votes = three_raw.split(\" \")[0]\n",
    "\n",
    "        two_raw = ratings_array[3].find('div', class_='RatingsHistogram__labelTotal').get_text()\n",
    "        two_votes = two_raw.split(\" \")[0]\n",
    "\n",
    "        first_raw = ratings_array[4].find('div', class_='RatingsHistogram__labelTotal').get_text()\n",
    "        first_votes = first_raw.split(\" \")[0]\n",
    "    except (AttributeError, IndexError):\n",
    "        five_votes = four_votes = three_votes = two_votes = first_votes = None\n",
    "\n",
    "    data = {\n",
    "        'name': [name],\n",
    "        'date': [date_var],\n",
    "        'author': [author],\n",
    "        'length': [length_var],\n",
    "        'rating count': [ratings_count_array[0]],\n",
    "        'review count': [reviews_count_array[0]],\n",
    "        '5 count rate': [five_votes],\n",
    "        '4 count rate': [four_votes],\n",
    "        '3 count rate': [three_votes],\n",
    "        '2 count rate': [two_votes],\n",
    "        '1 count rate': [first_votes],\n",
    "        'rating': [rating_num]\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310a600b",
   "metadata": {},
   "source": [
    "Using function random from 1 to 1000000, we get a different URL page each loop, and every URL is a different book.\n",
    "\n",
    "For each book we reach, we run function \"get_data_from_goodreads_url\" on it, and thus we collect specific data on each book individually, and appends the extracted data to a DataFrame until the DataFrame reaches 6000 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6517fd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = ['name', 'date','author','length','rating count','review count','5 count rate','4 count rate','3 count rate','2 count rate','1 count rate','rating']\n",
    "df = pd.DataFrame(columns=feature_columns)\n",
    "rand = random.randrange(1, 1000000)\n",
    "book = \"https://www.goodreads.com/book/show/{}\".format(rand)\n",
    "\n",
    "while df.shape[0] < 6000:\n",
    "    try:\n",
    "        rand = random.randrange(1, 1000000)\n",
    "        book = \"https://www.goodreads.com/book/show/{}\".format(rand)\n",
    "        temp_df = get_data_from_goodreads_url(book)\n",
    "        df = pd.concat([df, temp_df], ignore_index=True)\n",
    "        time.sleep(6)\n",
    "    except:\n",
    "        continue\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e090f915",
   "metadata": {},
   "source": [
    "exports the DataFrame `df` to a CSV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fb38f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('booksProject.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bc20ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660aa0a0",
   "metadata": {},
   "source": [
    "After starting the cleaning, it seemed that the amount of books decreased significantly, therefore it was decided to bring more books from the site in order to increase the DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9baf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('booksProject1.csv')\n",
    "df2 = pd.read_csv('booksProject2.csv')\n",
    "\n",
    "df1 = df1.drop('Unnamed: 0', axis=1)\n",
    "df2 = df2.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "df = pd.concat([df1, df2])\n",
    "\n",
    "df.to_csv('combined_books.csv')\n",
    "\n",
    "df.shape[0]\n",
    "total_data = df.shape[0] * df.shape[1]\n",
    "total_data\n",
    "df.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842eb669",
   "metadata": {},
   "source": [
    "Getting information about the amount of data we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ade40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1be5292",
   "metadata": {},
   "source": [
    " ## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c855fc42",
   "metadata": {},
   "source": [
    "Downloading duplicates, books that have been entered into DF more than once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fde27be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cf8464",
   "metadata": {},
   "source": [
    "deleting any non-numeric value in the 'Length' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db104c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[pd.to_numeric(df['length'], errors='coerce').notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84d5814",
   "metadata": {},
   "source": [
    "Every column that contains information with commas we replace the comma with nothing to delete the comma, for example the number 10,000 will become 10000.\n",
    "\n",
    "And basically every place where the number is represented in a way that is not INT - we will convert it to INT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e94efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = ['length', 'rating count', 'review count', '5 count rate', '4 count rate', '3 count rate', '2 count rate', '1 count rate']\n",
    "for column in attributes:\n",
    "    df[column] = df[column].apply(lambda x: int(str(x).replace(',', '')))\n",
    "    \n",
    "df[attributes] = df[attributes].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec762bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "We will use function A to obtain descriptive statistics of D, and the distribution and shape of the numerical column distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fbd666",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1827f4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961ca13d",
   "metadata": {},
   "source": [
    "All rows in the df containing at least one missing value will be removed, and the DataFrame df will be updated with the modified version.\n",
    "\n",
    "We will eliminate lines where the rating is equal to 0 since we want to examine the rating of the book, a result of 0 does not give us any data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03cd771",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=0, how='any', inplace=True)\n",
    "df = df[df['rating'] != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abf791f",
   "metadata": {},
   "source": [
    "We will convert the 'date' to an int number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e257c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = df['date'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9b27ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea980c9",
   "metadata": {},
   "source": [
    "The values in the 'rating' column of df will be rounded to one decimal place, and the DataFrame df will be updated.\n",
    "\n",
    "Get the count of each unique rating value in the 'rating' column, with the values displayed in descending order of their counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebab7268",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rating'] = df['rating'].round(decimals=1)\n",
    "df['rating'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6909d726",
   "metadata": {},
   "source": [
    "#Outliers handling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844456c5",
   "metadata": {},
   "source": [
    "In the following steps we will download all the exceptions that exist in the columns: 'rating count', 'date', 'length', 'review count', using box plot which shows us in a visual way who are the outliers, and therefore we will set an upper limit and a lower limit and remove all those that are outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcf5e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=df['rating count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a509db",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_bound = 0  \n",
    "upper_bound = 20000  \n",
    "\n",
    "df = df[(df['rating count'] >= lower_bound) & (df['rating count'] <= upper_bound)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17614498",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=df['rating count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170aed64",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68816986",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_bound = 1800  \n",
    "upper_bound = 2023  \n",
    "\n",
    "df = df[(df['date'] >= lower_bound) & (df['date'] <= upper_bound)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3cee2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6c5a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=df['length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec30c8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_bound = 70  \n",
    "upper_bound = 900 \n",
    "\n",
    "df = df[(df['length'] >= lower_bound) & (df['length'] <= upper_bound)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abe19c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=df['length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4c372c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=df['review count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a80038",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_bound = 0  \n",
    "upper_bound = 1500  \n",
    "\n",
    "df = df[(df['review count'] >= lower_bound) & (df['review count'] <= upper_bound)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb70541",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=df['review count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb9dca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review count'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9456f01",
   "metadata": {},
   "source": [
    "removes a random subset of rows with a 'review count' value of 0 from the DataFrame df, limiting the number of rows dropped to the limit value if it exceeds the number of rows with a 'review count' of 0. The printed output displays the updated value counts of the 'review count' column after the rows are dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf2a568",
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = 650\n",
    "\n",
    "zero_indices = df[df['review count'] == 0].index\n",
    "sampled_indices = np.random.choice(zero_indices, size=min(limit, len(zero_indices)), replace=False)\n",
    "df.drop(sampled_indices, inplace=True)\n",
    "\n",
    "print(df['review count'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168057ee",
   "metadata": {},
   "source": [
    "Getting information about the amount of data we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd502941",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00b3e34",
   "metadata": {},
   "source": [
    "This code generates a histogram to visualize the distribution of ratings in the DataFrame df. The x-axis represents the rating values, and the y-axis represents the number of books falling within each rating range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03aa099a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df['rating'], bins=5)\n",
    "plt.xlabel('rating')\n",
    "plt.ylabel('number of books')\n",
    "plt.show()\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23021f90",
   "metadata": {},
   "source": [
    "The code filters the DataFrame df to include only rows with a rating of 4.0 and limits the number of rows to 300. Any excess rows beyond this limit are dropped from the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1e0af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_4_indices = df[df['rating'] == 4.0].index\n",
    "excess_indices = rating_4_indices[:300]\n",
    "df.drop(excess_indices, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58018a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df['rating'], bins=5)\n",
    "plt.xlabel('rating')\n",
    "plt.ylabel('number of books')\n",
    "plt.show()\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd77ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rating'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0951a0a9",
   "metadata": {},
   "source": [
    "Count the number of books in each length category,Data definition and display of the pie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7341eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "length_counts = df['length'].value_counts().head(10)\n",
    "\n",
    "# Plot the pie chart\n",
    "plt.pie(length_counts, labels=length_counts.index, autopct='%1.1f%%')\n",
    "\n",
    "plt.title('Distribution of Book Length')\n",
    "plt.axis('equal')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a4052c",
   "metadata": {},
   "source": [
    "We can see the most common length of the books is 256, then 192\n",
    "\n",
    "By using 'Scatter Plot' we present the ratio between the number of ratings and the number of pages of the book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455f9570",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['length']\n",
    "y = df['rating']\n",
    "\n",
    "plt.scatter(x, y)\n",
    "\n",
    "plt.xlabel('Length')\n",
    "plt.ylabel('Rating')\n",
    "plt.title('Scatter Plot of Length vs Rating')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dde5709",
   "metadata": {},
   "source": [
    "Here we can see the relationship between the length and the ratings, that actually the fewer pages there are the fewer ratings, which indicates a preference for shorter books\n",
    "\n",
    "By using scatter plot again we want to present the relationship between the number of ratings and the final rating of the book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94e4dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = df['rating']\n",
    "y = df['rating count']\n",
    "\n",
    "plt.scatter(x, y)\n",
    "\n",
    "plt.xlabel('rating')\n",
    "plt.ylabel('Rating Count')\n",
    "plt.title('Scatter Plot of rating vs Rating Count')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2563b10b",
   "metadata": {},
   "source": [
    "We can see that the most highly rated books are the books rated between 3.5 and 4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17f7af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['review count']\n",
    "y = df['rating count']\n",
    "\n",
    "plt.scatter(x, y)\n",
    "\n",
    "plt.xlabel('review count')\n",
    "plt.ylabel('Rating count')\n",
    "plt.title('Scatter Plot of review count vs Rating count')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3de77d",
   "metadata": {},
   "source": [
    "Here we can see that when there is less 'Rating count' there is less 'Reviews count'\n",
    "\n",
    "Using BoxPlot we want to visualize the distribution of the 'rating' column in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec11708",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.boxplot(column='rating')\n",
    "plt.xlabel('rating')\n",
    "plt.ylabel('counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8586c7d4",
   "metadata": {},
   "source": [
    "It seems that from 2.5 to 5 these are the most common and below 2.0 there are fewer ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6695376b",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['length', 'rating', 'rating count' ,'review count','5 count rate','4 count rate','3 count rate','2 count rate','1 count rate']\n",
    "selected_df = df[columns]\n",
    "\n",
    "correlation_matrix = selected_df.corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.1%', cmap='coolwarm', cbar=True)\n",
    "\n",
    "plt.title('Correlation Matrix with Percentage')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b714bd",
   "metadata": {},
   "source": [
    "These lines set the title for the plot and display the heatmap.\n",
    "\n",
    "The resulting plot shows the correlations between the selected columns, with higher values indicating stronger correlations.\n",
    "\n",
    "In this case, the only strong correlation is between 'rating count' and 'review count', which is logical because if a user rates the book, most of the time he will also review it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201e4553",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae17fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179a8e2a",
   "metadata": {},
   "source": [
    "We want to save all the data we changed to a new DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9ba7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('df_after_changes.csv', index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8755ebf9",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665ed502",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('df_after_changes.csv')\n",
    "#df = df.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf7f593",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bae849",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df['name'] = label_encoder.fit_transform(df['name'])\n",
    "df['author'] = label_encoder.fit_transform(df['author'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1f3308",
   "metadata": {},
   "outputs": [],
   "source": [
    "Splitting the data as we learned throughout the course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea657d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('rating', axis=1)\n",
    "y = df['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b845c643",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d157191e",
   "metadata": {},
   "source": [
    "Defining the parameters we want to test and creating a pipeline as documentation suggested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb05875",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape[0]*df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af066ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_param_grid = {\n",
    "    'linearregression__fit_intercept': [True, False],\n",
    "}\n",
    "\n",
    "rf_param_grid = {\n",
    "    'randomforestregressor__n_estimators': [100, 200, 300],\n",
    "    'randomforestregressor__max_depth': [None, 5, 10],\n",
    "    'randomforestregressor__min_samples_split': [2, 5, 10],\n",
    "    'randomforestregressor__min_samples_leaf': [1, 2, 4],\n",
    "}\n",
    "\n",
    "linear_model = make_pipeline(StandardScaler(), LinearRegression())\n",
    "\n",
    "rf_model = make_pipeline(StandardScaler(), RandomForestRegressor())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85788d21",
   "metadata": {},
   "source": [
    "Here we performs grid search for both Linear Regression and Random Forest Regression models. It uses scikit-learn's GridSearchCV function to search for the best combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913b9d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_grid_search = GridSearchCV(estimator=linear_model, param_grid=linear_param_grid, cv=3)\n",
    "linear_grid_search.fit(X_train, y_train)\n",
    "best_linear_model = linear_grid_search.best_estimator_\n",
    "\n",
    "rf_grid_search = GridSearchCV(estimator=rf_model, param_grid=rf_param_grid, cv=3)\n",
    "rf_grid_search.fit(X_train, y_train)\n",
    "#best_rf_model = rf_grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ceb5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_predictions = best_linear_model.predict(X_test)\n",
    "linear_mse = mean_squared_error(y_test, linear_predictions)\n",
    "linear_rmse = linear_mse ** 0.5\n",
    "linear_r2 = r2_score(y_test, linear_predictions)\n",
    "\n",
    "rf_predictions = best_rf_model.predict(X_test)\n",
    "rf_mse = mean_squared_error(y_test, rf_predictions)\n",
    "rf_rmse = rf_mse ** 0.5\n",
    "rf_r2 = r2_score(y_test, rf_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0774acb",
   "metadata": {},
   "source": [
    "### Printing the evaluation metrics of both models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6ffa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Linear Regression - RMSE:\", linear_rmse, \"R2:\", linear_r2)\n",
    "print(\"Best Linear Regression hyperparameters:\", linear_grid_search.best_params_)\n",
    "\n",
    "print(\"Random Forest Regression - RMSE:\", rf_rmse, \"R2:\", rf_r2)\n",
    "print(\"Best Random Forest hyperparameters:\", rf_grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06d06c5",
   "metadata": {},
   "source": [
    "Linear Regression - RMSE: 0.5193198963157538 R2: 0.036852363321188575\n",
    "Best Linear Regression hyperparameters: {'linearregression__fit_intercept': True}\n",
    "Random Forest Regression - RMSE: 0.06531829982154097 R2: 0.9847632380058123\n",
    "Best Random Forest hyperparameters: {'randomforestregressor__max_depth': None, 'randomforestregressor__min_samples_leaf': 1, 'randomforestregressor__min_samples_split': 2, 'randomforestregressor__n_estimators': 200}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf6329e",
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'Random Forest Regression'\n",
    "\n",
    "r2 = 0.9847632380058123\n",
    "rmse = 0.06531829982154097\n",
    "\n",
    "bar_width = 0.35\n",
    "\n",
    "bar_positions = np.arange(2)\n",
    "\n",
    "plt.bar(bar_positions, [r2, rmse], bar_width, align='center')\n",
    "\n",
    "plt.xlabel('Metrics')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Comparison of R2 and RMSE - Random Forest Regression')\n",
    "plt.xticks(bar_positions, ['R2', 'RMSE'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbcb900",
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'Linear Regression'\n",
    "\n",
    "r2 = 0.036852363321188575\n",
    "rmse =  0.5193198963157538\n",
    "\n",
    "bar_width = 0.35\n",
    "\n",
    "bar_positions = np.arange(2)\n",
    "\n",
    "plt.bar(bar_positions, [r2, rmse], bar_width, align='center')\n",
    "\n",
    "plt.xlabel('Metrics')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Comparison of R2 and RMSE - Linear Regression')\n",
    "plt.xticks(bar_positions, ['R2', 'RMSE'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7902d4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "data = [\n",
    "    ['Random Forest Regression', 0.9847632380058123, 0.06531829982154097],\n",
    "    ['Linear Regression', 0.036852363321188575, 0.5193198963157538]\n",
    "]\n",
    "\n",
    "headers = ['Model', 'R2', 'RMSE']\n",
    "\n",
    "colored_headers = [Back.CYAN+ Fore.BLACK + header + Style.RESET_ALL for header in headers]\n",
    "\n",
    "table = tabulate(data, colored_headers, tablefmt='fancy_grid')\n",
    "print(table)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
